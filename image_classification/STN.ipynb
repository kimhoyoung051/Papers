{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Transformer Networks (STN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Paper: [2015.06.05] Spatial Transformer Networks (STN)\n",
    "- https://arxiv.org/abs/1506.02025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Package load]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 2.2.2\n",
      "pytorch version: 2.2.2\n",
      "GPU 사용 가능 여부: False\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Model: STN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://pytorch.org/tutorials/intermediate/spatial_transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(STN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "        # Spatial transformer localization-network\n",
    "        self.localization = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Regressor for the 3 * 2 affine matrix -> theta 값을 만들어내기\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * 3 * 3, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)\n",
    "        )\n",
    "\n",
    "        # Initialize the weights/bias (항등 행렬로)\n",
    "        self.fc_loc[2].weight.data.fill_(0)\n",
    "        self.fc_loc[2].bias.data = torch.FloatTensor([1, 0, 0, 0, 1, 0])\n",
    "\n",
    "    def stn(self, x):\n",
    "        x_stn = self.localization(x)            # localization 통과 -> output: (10, 3, 3)\n",
    "        x_stn = x_stn.view(-1, 10 * 3 * 3)      # Theta 값 만들기 위해 행렬 조절\n",
    "        theta = self.fc_loc(x_stn)              # Regressor 통과해서 Theta 만들기\n",
    "        theta = theta.view(-1, 2, 3)            # theta를 2,3로 만들기\n",
    "\n",
    "        grid = F.affine_grid(theta, x.size())   # (N, 2, 3)의 theta를 받아서 target output size인 x의 size만큼으로 출력 (Affine 시키는 것)\n",
    "        x = F.grid_sample(x, grid)              # input과 grid가 주어졌을 때, grid의 입력 값과 픽셀 위치를 사용하여 최종 output을 계산\n",
    "                                                # 참고: https://gaussian37.github.io/dl-pytorch-snippets/#fgrid_sample-%ED%95%A8%EC%88%98-%EC%82%AC%EC%9A%A9-%EC%98%88%EC%A0%9C-1\n",
    "\n",
    "        return x    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # 입력을 변환\n",
    "        x = self.stn(x)\n",
    "\n",
    "        # 일반적인 forward pass를 수행\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn = STN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\for_learning\\lib\\site-packages\\torch\\nn\\functional.py:4377: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\miniconda3\\envs\\for_learning\\lib\\site-packages\\torch\\nn\\functional.py:4316: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.Tensor(np.random.randint(1, 255, size=(1, 1, 28, 28))) # MNIST size\n",
    "stn(temp).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 22, 22]             400\n",
      "         MaxPool2d-2            [-1, 8, 11, 11]               0\n",
      "              ReLU-3            [-1, 8, 11, 11]               0\n",
      "            Conv2d-4             [-1, 10, 7, 7]           2,010\n",
      "         MaxPool2d-5             [-1, 10, 3, 3]               0\n",
      "              ReLU-6             [-1, 10, 3, 3]               0\n",
      "            Linear-7                   [-1, 32]           2,912\n",
      "              ReLU-8                   [-1, 32]               0\n",
      "            Linear-9                    [-1, 6]             198\n",
      "           Conv2d-10           [-1, 10, 24, 24]             260\n",
      "           Conv2d-11             [-1, 20, 8, 8]           5,020\n",
      "        Dropout2d-12             [-1, 20, 8, 8]               0\n",
      "           Linear-13                   [-1, 50]          16,050\n",
      "           Linear-14                   [-1, 10]             510\n",
      "================================================================\n",
      "Total params: 27,360\n",
      "Trainable params: 27,360\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.11\n",
      "Params size (MB): 0.10\n",
      "Estimated Total Size (MB): 0.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(stn, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name):depth-idx)        Input Shape          Kernel Shape         Output Shape         Param %\n",
       "========================================================================================================================\n",
       "STN (STN)                                [1, 1, 28, 28]       --                   [1, 10]                   --\n",
       "├─Sequential (localization): 1-1         [1, 1, 28, 28]       --                   [1, 10, 3, 3]             --\n",
       "│    └─Conv2d (0): 2-1                   [1, 1, 28, 28]       [7, 7]               [1, 8, 22, 22]         1.46%\n",
       "│    └─MaxPool2d (1): 2-2                [1, 8, 22, 22]       2                    [1, 8, 11, 11]            --\n",
       "│    └─ReLU (2): 2-3                     [1, 8, 11, 11]       --                   [1, 8, 11, 11]            --\n",
       "│    └─Conv2d (3): 2-4                   [1, 8, 11, 11]       [5, 5]               [1, 10, 7, 7]          7.35%\n",
       "│    └─MaxPool2d (4): 2-5                [1, 10, 7, 7]        2                    [1, 10, 3, 3]             --\n",
       "│    └─ReLU (5): 2-6                     [1, 10, 3, 3]        --                   [1, 10, 3, 3]             --\n",
       "├─Sequential (fc_loc): 1-2               [1, 90]              --                   [1, 6]                    --\n",
       "│    └─Linear (0): 2-7                   [1, 90]              --                   [1, 32]               10.64%\n",
       "│    └─ReLU (1): 2-8                     [1, 32]              --                   [1, 32]                   --\n",
       "│    └─Linear (2): 2-9                   [1, 32]              --                   [1, 6]                 0.72%\n",
       "├─Conv2d (conv1): 1-3                    [1, 1, 28, 28]       [5, 5]               [1, 10, 24, 24]        0.95%\n",
       "├─Conv2d (conv2): 1-4                    [1, 10, 12, 12]      [5, 5]               [1, 20, 8, 8]         18.35%\n",
       "├─Dropout2d (conv2_drop): 1-5            [1, 20, 8, 8]        --                   [1, 20, 8, 8]             --\n",
       "├─Linear (fc1): 1-6                      [1, 320]             --                   [1, 50]               58.66%\n",
       "├─Linear (fc2): 1-7                      [1, 50]              --                   [1, 10]                1.86%\n",
       "========================================================================================================================\n",
       "Total params: 27,360\n",
       "Trainable params: 27,360\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.78\n",
       "========================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.09\n",
       "Params size (MB): 0.11\n",
       "Estimated Total Size (MB): 0.20\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(stn, input_size=(1, 1, 28, 28), col_width=20, depth=40, row_settings=[\"depth\", \"var_names\"], col_names=[\"input_size\", \"kernel_size\", \"output_size\", \"params_percent\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
