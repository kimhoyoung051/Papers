{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-activation ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Paper: [2016.03.16] Identity Mappings in Deep Residual Networks\n",
    "- https://arxiv.org/abs/1603.05027"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Package load]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch version: 2.2.2\n",
      "pytorch version: 2.2.2\n",
      "GPU 사용 가능 여부: False\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Model: Preactivation ResNet 152]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고: https://github.com/weiaicunzai/pytorch-cifar100/blob/master/models/preactresnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Bottleneck"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n",
    "\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, 1)\n",
    "        )\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        short_cut = x\n",
    "        residual = self.residual(x)\n",
    "        if self.downsample is not None:\n",
    "            short_cut = self.downsample(x)\n",
    "        return residual + short_cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### Pre activation ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=1000, init_weights=True):\n",
    "        super().__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer2 = self._make_layers(block, num_blocks[0], 64, 1)\n",
    "        self.layer3 = self._make_layers(block, num_blocks[1], 128, 2)\n",
    "        self.layer4 = self._make_layers(block, num_blocks[2], 256, 2)\n",
    "        self.layer5 = self._make_layers(block, num_blocks[3], 512, 2)\n",
    "        \n",
    "        self.last_act = nn.Sequential(\n",
    "            nn.BatchNorm2d(512 * BottleNeck.expansion),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        \n",
    "        self.linear = nn.Linear(512 * BottleNeck.expansion, num_classes)\n",
    "\n",
    "        # weights Initialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _make_layers(self, block, block_num, out_channels, stride):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:   \n",
    "                            # inplanes = 64 != 64 * 4 (bottleneck의 expansion)\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * block.expansion, 1, stride=stride), #conv(in_channel, in_channel x expansion, 1)\n",
    "                nn.BatchNorm2d(out_channels * block.expansion), #batchnrom2d(256)\n",
    "            )\n",
    "            # 원래 feature 수 맞추려고 쓰는데 여기서는 channel을 맞추는 용도로 사용함\n",
    "        \n",
    "        layers = []\n",
    "\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
    "            # stride 2인 경우 이 때 한 번 2가 들어감\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        for _ in range(1, block_num):\n",
    "            # 위에서 한 번 append 했으니 block_num-1만큼 append를 함\n",
    "            layers.append(block(self.in_channels, out_channels, 1))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.last_act(x)\n",
    "        x = self.avg_pool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preresnet152 = PreActResNet(BottleNeck, [3,8,36,3], 1000, True).to(device) \n",
    "# 1(conv1) + 9(layer1) + 24(layer2) +108(layer3) + 9(layer4) +1(fc)= preactivation ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreActResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (3): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (4): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (5): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (6): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (7): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (8): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (9): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (10): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (11): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (12): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (13): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (14): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (15): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (16): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (17): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (18): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (19): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (20): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (21): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (22): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (23): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (24): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (25): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (26): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (27): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (28): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (29): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (30): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (31): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (32): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (33): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (34): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (35): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (2): BottleNeck(\n",
       "      (residual): Sequential(\n",
       "        (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (7): ReLU(inplace=True)\n",
       "        (8): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (last_act): Sequential(\n",
       "    (0): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (linear): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preresnet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = torch.Tensor(np.random.randint(1, 255, size=(1, 3, 224, 224)))\n",
    "preresnet152(temp).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "       BatchNorm2d-4         [-1, 64, 224, 224]             128\n",
      "              ReLU-5         [-1, 64, 224, 224]               0\n",
      "            Conv2d-6         [-1, 64, 224, 224]           4,160\n",
      "       BatchNorm2d-7         [-1, 64, 224, 224]             128\n",
      "              ReLU-8         [-1, 64, 224, 224]               0\n",
      "            Conv2d-9         [-1, 64, 224, 224]          36,928\n",
      "      BatchNorm2d-10         [-1, 64, 224, 224]             128\n",
      "             ReLU-11         [-1, 64, 224, 224]               0\n",
      "           Conv2d-12        [-1, 256, 224, 224]          16,640\n",
      "           Conv2d-13        [-1, 256, 224, 224]          16,640\n",
      "      BatchNorm2d-14        [-1, 256, 224, 224]             512\n",
      "       BottleNeck-15        [-1, 256, 224, 224]               0\n",
      "      BatchNorm2d-16        [-1, 256, 224, 224]             512\n",
      "             ReLU-17        [-1, 256, 224, 224]               0\n",
      "           Conv2d-18         [-1, 64, 224, 224]          16,448\n",
      "      BatchNorm2d-19         [-1, 64, 224, 224]             128\n",
      "             ReLU-20         [-1, 64, 224, 224]               0\n",
      "           Conv2d-21         [-1, 64, 224, 224]          36,928\n",
      "      BatchNorm2d-22         [-1, 64, 224, 224]             128\n",
      "             ReLU-23         [-1, 64, 224, 224]               0\n",
      "           Conv2d-24        [-1, 256, 224, 224]          16,640\n",
      "       BottleNeck-25        [-1, 256, 224, 224]               0\n",
      "      BatchNorm2d-26        [-1, 256, 224, 224]             512\n",
      "             ReLU-27        [-1, 256, 224, 224]               0\n",
      "           Conv2d-28         [-1, 64, 224, 224]          16,448\n",
      "      BatchNorm2d-29         [-1, 64, 224, 224]             128\n",
      "             ReLU-30         [-1, 64, 224, 224]               0\n",
      "           Conv2d-31         [-1, 64, 224, 224]          36,928\n",
      "      BatchNorm2d-32         [-1, 64, 224, 224]             128\n",
      "             ReLU-33         [-1, 64, 224, 224]               0\n",
      "           Conv2d-34        [-1, 256, 224, 224]          16,640\n",
      "       BottleNeck-35        [-1, 256, 224, 224]               0\n",
      "      BatchNorm2d-36        [-1, 256, 224, 224]             512\n",
      "             ReLU-37        [-1, 256, 224, 224]               0\n",
      "           Conv2d-38        [-1, 128, 112, 112]          32,896\n",
      "      BatchNorm2d-39        [-1, 128, 112, 112]             256\n",
      "             ReLU-40        [-1, 128, 112, 112]               0\n",
      "           Conv2d-41        [-1, 128, 112, 112]         147,584\n",
      "      BatchNorm2d-42        [-1, 128, 112, 112]             256\n",
      "             ReLU-43        [-1, 128, 112, 112]               0\n",
      "           Conv2d-44        [-1, 512, 112, 112]          66,048\n",
      "           Conv2d-45        [-1, 512, 112, 112]         131,584\n",
      "      BatchNorm2d-46        [-1, 512, 112, 112]           1,024\n",
      "       BottleNeck-47        [-1, 512, 112, 112]               0\n",
      "      BatchNorm2d-48        [-1, 512, 112, 112]           1,024\n",
      "             ReLU-49        [-1, 512, 112, 112]               0\n",
      "           Conv2d-50        [-1, 128, 112, 112]          65,664\n",
      "      BatchNorm2d-51        [-1, 128, 112, 112]             256\n",
      "             ReLU-52        [-1, 128, 112, 112]               0\n",
      "           Conv2d-53        [-1, 128, 112, 112]         147,584\n",
      "      BatchNorm2d-54        [-1, 128, 112, 112]             256\n",
      "             ReLU-55        [-1, 128, 112, 112]               0\n",
      "           Conv2d-56        [-1, 512, 112, 112]          66,048\n",
      "       BottleNeck-57        [-1, 512, 112, 112]               0\n",
      "      BatchNorm2d-58        [-1, 512, 112, 112]           1,024\n",
      "             ReLU-59        [-1, 512, 112, 112]               0\n",
      "           Conv2d-60        [-1, 128, 112, 112]          65,664\n",
      "      BatchNorm2d-61        [-1, 128, 112, 112]             256\n",
      "             ReLU-62        [-1, 128, 112, 112]               0\n",
      "           Conv2d-63        [-1, 128, 112, 112]         147,584\n",
      "      BatchNorm2d-64        [-1, 128, 112, 112]             256\n",
      "             ReLU-65        [-1, 128, 112, 112]               0\n",
      "           Conv2d-66        [-1, 512, 112, 112]          66,048\n",
      "       BottleNeck-67        [-1, 512, 112, 112]               0\n",
      "      BatchNorm2d-68        [-1, 512, 112, 112]           1,024\n",
      "             ReLU-69        [-1, 512, 112, 112]               0\n",
      "           Conv2d-70        [-1, 128, 112, 112]          65,664\n",
      "      BatchNorm2d-71        [-1, 128, 112, 112]             256\n",
      "             ReLU-72        [-1, 128, 112, 112]               0\n",
      "           Conv2d-73        [-1, 128, 112, 112]         147,584\n",
      "      BatchNorm2d-74        [-1, 128, 112, 112]             256\n",
      "             ReLU-75        [-1, 128, 112, 112]               0\n",
      "           Conv2d-76        [-1, 512, 112, 112]          66,048\n",
      "       BottleNeck-77        [-1, 512, 112, 112]               0\n",
      "      BatchNorm2d-78        [-1, 512, 112, 112]           1,024\n",
      "             ReLU-79        [-1, 512, 112, 112]               0\n",
      "           Conv2d-80        [-1, 128, 112, 112]          65,664\n",
      "      BatchNorm2d-81        [-1, 128, 112, 112]             256\n",
      "             ReLU-82        [-1, 128, 112, 112]               0\n",
      "           Conv2d-83        [-1, 128, 112, 112]         147,584\n",
      "      BatchNorm2d-84        [-1, 128, 112, 112]             256\n",
      "             ReLU-85        [-1, 128, 112, 112]               0\n",
      "           Conv2d-86        [-1, 512, 112, 112]          66,048\n",
      "       BottleNeck-87        [-1, 512, 112, 112]               0\n",
      "      BatchNorm2d-88        [-1, 512, 112, 112]           1,024\n",
      "             ReLU-89        [-1, 512, 112, 112]               0\n",
      "           Conv2d-90        [-1, 128, 112, 112]          65,664\n",
      "      BatchNorm2d-91        [-1, 128, 112, 112]             256\n",
      "             ReLU-92        [-1, 128, 112, 112]               0\n",
      "           Conv2d-93        [-1, 128, 112, 112]         147,584\n",
      "      BatchNorm2d-94        [-1, 128, 112, 112]             256\n",
      "             ReLU-95        [-1, 128, 112, 112]               0\n",
      "           Conv2d-96        [-1, 512, 112, 112]          66,048\n",
      "       BottleNeck-97        [-1, 512, 112, 112]               0\n",
      "      BatchNorm2d-98        [-1, 512, 112, 112]           1,024\n",
      "             ReLU-99        [-1, 512, 112, 112]               0\n",
      "          Conv2d-100        [-1, 128, 112, 112]          65,664\n",
      "     BatchNorm2d-101        [-1, 128, 112, 112]             256\n",
      "            ReLU-102        [-1, 128, 112, 112]               0\n",
      "          Conv2d-103        [-1, 128, 112, 112]         147,584\n",
      "     BatchNorm2d-104        [-1, 128, 112, 112]             256\n",
      "            ReLU-105        [-1, 128, 112, 112]               0\n",
      "          Conv2d-106        [-1, 512, 112, 112]          66,048\n",
      "      BottleNeck-107        [-1, 512, 112, 112]               0\n",
      "     BatchNorm2d-108        [-1, 512, 112, 112]           1,024\n",
      "            ReLU-109        [-1, 512, 112, 112]               0\n",
      "          Conv2d-110        [-1, 128, 112, 112]          65,664\n",
      "     BatchNorm2d-111        [-1, 128, 112, 112]             256\n",
      "            ReLU-112        [-1, 128, 112, 112]               0\n",
      "          Conv2d-113        [-1, 128, 112, 112]         147,584\n",
      "     BatchNorm2d-114        [-1, 128, 112, 112]             256\n",
      "            ReLU-115        [-1, 128, 112, 112]               0\n",
      "          Conv2d-116        [-1, 512, 112, 112]          66,048\n",
      "      BottleNeck-117        [-1, 512, 112, 112]               0\n",
      "     BatchNorm2d-118        [-1, 512, 112, 112]           1,024\n",
      "            ReLU-119        [-1, 512, 112, 112]               0\n",
      "          Conv2d-120          [-1, 256, 56, 56]         131,328\n",
      "     BatchNorm2d-121          [-1, 256, 56, 56]             512\n",
      "            ReLU-122          [-1, 256, 56, 56]               0\n",
      "          Conv2d-123          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-124          [-1, 256, 56, 56]             512\n",
      "            ReLU-125          [-1, 256, 56, 56]               0\n",
      "          Conv2d-126         [-1, 1024, 56, 56]         263,168\n",
      "          Conv2d-127         [-1, 1024, 56, 56]         525,312\n",
      "     BatchNorm2d-128         [-1, 1024, 56, 56]           2,048\n",
      "      BottleNeck-129         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-130         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-131         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-132          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-133          [-1, 256, 56, 56]             512\n",
      "            ReLU-134          [-1, 256, 56, 56]               0\n",
      "          Conv2d-135          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-136          [-1, 256, 56, 56]             512\n",
      "            ReLU-137          [-1, 256, 56, 56]               0\n",
      "          Conv2d-138         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-139         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-140         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-141         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-142          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-143          [-1, 256, 56, 56]             512\n",
      "            ReLU-144          [-1, 256, 56, 56]               0\n",
      "          Conv2d-145          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-146          [-1, 256, 56, 56]             512\n",
      "            ReLU-147          [-1, 256, 56, 56]               0\n",
      "          Conv2d-148         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-149         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-150         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-151         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-152          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-153          [-1, 256, 56, 56]             512\n",
      "            ReLU-154          [-1, 256, 56, 56]               0\n",
      "          Conv2d-155          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-156          [-1, 256, 56, 56]             512\n",
      "            ReLU-157          [-1, 256, 56, 56]               0\n",
      "          Conv2d-158         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-159         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-160         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-161         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-162          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-163          [-1, 256, 56, 56]             512\n",
      "            ReLU-164          [-1, 256, 56, 56]               0\n",
      "          Conv2d-165          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-166          [-1, 256, 56, 56]             512\n",
      "            ReLU-167          [-1, 256, 56, 56]               0\n",
      "          Conv2d-168         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-169         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-170         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-171         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-172          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-173          [-1, 256, 56, 56]             512\n",
      "            ReLU-174          [-1, 256, 56, 56]               0\n",
      "          Conv2d-175          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-176          [-1, 256, 56, 56]             512\n",
      "            ReLU-177          [-1, 256, 56, 56]               0\n",
      "          Conv2d-178         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-179         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-180         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-181         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-182          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-183          [-1, 256, 56, 56]             512\n",
      "            ReLU-184          [-1, 256, 56, 56]               0\n",
      "          Conv2d-185          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-186          [-1, 256, 56, 56]             512\n",
      "            ReLU-187          [-1, 256, 56, 56]               0\n",
      "          Conv2d-188         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-189         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-190         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-191         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-192          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-193          [-1, 256, 56, 56]             512\n",
      "            ReLU-194          [-1, 256, 56, 56]               0\n",
      "          Conv2d-195          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-196          [-1, 256, 56, 56]             512\n",
      "            ReLU-197          [-1, 256, 56, 56]               0\n",
      "          Conv2d-198         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-199         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-200         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-201         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-202          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-203          [-1, 256, 56, 56]             512\n",
      "            ReLU-204          [-1, 256, 56, 56]               0\n",
      "          Conv2d-205          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-206          [-1, 256, 56, 56]             512\n",
      "            ReLU-207          [-1, 256, 56, 56]               0\n",
      "          Conv2d-208         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-209         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-210         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-211         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-212          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-213          [-1, 256, 56, 56]             512\n",
      "            ReLU-214          [-1, 256, 56, 56]               0\n",
      "          Conv2d-215          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-216          [-1, 256, 56, 56]             512\n",
      "            ReLU-217          [-1, 256, 56, 56]               0\n",
      "          Conv2d-218         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-219         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-220         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-221         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-222          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-223          [-1, 256, 56, 56]             512\n",
      "            ReLU-224          [-1, 256, 56, 56]               0\n",
      "          Conv2d-225          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-226          [-1, 256, 56, 56]             512\n",
      "            ReLU-227          [-1, 256, 56, 56]               0\n",
      "          Conv2d-228         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-229         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-230         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-231         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-232          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-233          [-1, 256, 56, 56]             512\n",
      "            ReLU-234          [-1, 256, 56, 56]               0\n",
      "          Conv2d-235          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-236          [-1, 256, 56, 56]             512\n",
      "            ReLU-237          [-1, 256, 56, 56]               0\n",
      "          Conv2d-238         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-239         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-240         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-241         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-242          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-243          [-1, 256, 56, 56]             512\n",
      "            ReLU-244          [-1, 256, 56, 56]               0\n",
      "          Conv2d-245          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-246          [-1, 256, 56, 56]             512\n",
      "            ReLU-247          [-1, 256, 56, 56]               0\n",
      "          Conv2d-248         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-249         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-250         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-251         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-252          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-253          [-1, 256, 56, 56]             512\n",
      "            ReLU-254          [-1, 256, 56, 56]               0\n",
      "          Conv2d-255          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-256          [-1, 256, 56, 56]             512\n",
      "            ReLU-257          [-1, 256, 56, 56]               0\n",
      "          Conv2d-258         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-259         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-260         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-261         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-262          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-263          [-1, 256, 56, 56]             512\n",
      "            ReLU-264          [-1, 256, 56, 56]               0\n",
      "          Conv2d-265          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-266          [-1, 256, 56, 56]             512\n",
      "            ReLU-267          [-1, 256, 56, 56]               0\n",
      "          Conv2d-268         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-269         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-270         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-271         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-272          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-273          [-1, 256, 56, 56]             512\n",
      "            ReLU-274          [-1, 256, 56, 56]               0\n",
      "          Conv2d-275          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-276          [-1, 256, 56, 56]             512\n",
      "            ReLU-277          [-1, 256, 56, 56]               0\n",
      "          Conv2d-278         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-279         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-280         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-281         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-282          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-283          [-1, 256, 56, 56]             512\n",
      "            ReLU-284          [-1, 256, 56, 56]               0\n",
      "          Conv2d-285          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-286          [-1, 256, 56, 56]             512\n",
      "            ReLU-287          [-1, 256, 56, 56]               0\n",
      "          Conv2d-288         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-289         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-290         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-291         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-292          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-293          [-1, 256, 56, 56]             512\n",
      "            ReLU-294          [-1, 256, 56, 56]               0\n",
      "          Conv2d-295          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-296          [-1, 256, 56, 56]             512\n",
      "            ReLU-297          [-1, 256, 56, 56]               0\n",
      "          Conv2d-298         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-299         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-300         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-301         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-302          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-303          [-1, 256, 56, 56]             512\n",
      "            ReLU-304          [-1, 256, 56, 56]               0\n",
      "          Conv2d-305          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-306          [-1, 256, 56, 56]             512\n",
      "            ReLU-307          [-1, 256, 56, 56]               0\n",
      "          Conv2d-308         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-309         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-310         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-311         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-312          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-313          [-1, 256, 56, 56]             512\n",
      "            ReLU-314          [-1, 256, 56, 56]               0\n",
      "          Conv2d-315          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-316          [-1, 256, 56, 56]             512\n",
      "            ReLU-317          [-1, 256, 56, 56]               0\n",
      "          Conv2d-318         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-319         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-320         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-321         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-322          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-323          [-1, 256, 56, 56]             512\n",
      "            ReLU-324          [-1, 256, 56, 56]               0\n",
      "          Conv2d-325          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-326          [-1, 256, 56, 56]             512\n",
      "            ReLU-327          [-1, 256, 56, 56]               0\n",
      "          Conv2d-328         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-329         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-330         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-331         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-332          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-333          [-1, 256, 56, 56]             512\n",
      "            ReLU-334          [-1, 256, 56, 56]               0\n",
      "          Conv2d-335          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-336          [-1, 256, 56, 56]             512\n",
      "            ReLU-337          [-1, 256, 56, 56]               0\n",
      "          Conv2d-338         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-339         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-340         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-341         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-342          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-343          [-1, 256, 56, 56]             512\n",
      "            ReLU-344          [-1, 256, 56, 56]               0\n",
      "          Conv2d-345          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-346          [-1, 256, 56, 56]             512\n",
      "            ReLU-347          [-1, 256, 56, 56]               0\n",
      "          Conv2d-348         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-349         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-350         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-351         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-352          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-353          [-1, 256, 56, 56]             512\n",
      "            ReLU-354          [-1, 256, 56, 56]               0\n",
      "          Conv2d-355          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-356          [-1, 256, 56, 56]             512\n",
      "            ReLU-357          [-1, 256, 56, 56]               0\n",
      "          Conv2d-358         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-359         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-360         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-361         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-362          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-363          [-1, 256, 56, 56]             512\n",
      "            ReLU-364          [-1, 256, 56, 56]               0\n",
      "          Conv2d-365          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-366          [-1, 256, 56, 56]             512\n",
      "            ReLU-367          [-1, 256, 56, 56]               0\n",
      "          Conv2d-368         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-369         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-370         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-371         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-372          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-373          [-1, 256, 56, 56]             512\n",
      "            ReLU-374          [-1, 256, 56, 56]               0\n",
      "          Conv2d-375          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-376          [-1, 256, 56, 56]             512\n",
      "            ReLU-377          [-1, 256, 56, 56]               0\n",
      "          Conv2d-378         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-379         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-380         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-381         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-382          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-383          [-1, 256, 56, 56]             512\n",
      "            ReLU-384          [-1, 256, 56, 56]               0\n",
      "          Conv2d-385          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-386          [-1, 256, 56, 56]             512\n",
      "            ReLU-387          [-1, 256, 56, 56]               0\n",
      "          Conv2d-388         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-389         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-390         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-391         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-392          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-393          [-1, 256, 56, 56]             512\n",
      "            ReLU-394          [-1, 256, 56, 56]               0\n",
      "          Conv2d-395          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-396          [-1, 256, 56, 56]             512\n",
      "            ReLU-397          [-1, 256, 56, 56]               0\n",
      "          Conv2d-398         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-399         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-400         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-401         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-402          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-403          [-1, 256, 56, 56]             512\n",
      "            ReLU-404          [-1, 256, 56, 56]               0\n",
      "          Conv2d-405          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-406          [-1, 256, 56, 56]             512\n",
      "            ReLU-407          [-1, 256, 56, 56]               0\n",
      "          Conv2d-408         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-409         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-410         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-411         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-412          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-413          [-1, 256, 56, 56]             512\n",
      "            ReLU-414          [-1, 256, 56, 56]               0\n",
      "          Conv2d-415          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-416          [-1, 256, 56, 56]             512\n",
      "            ReLU-417          [-1, 256, 56, 56]               0\n",
      "          Conv2d-418         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-419         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-420         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-421         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-422          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-423          [-1, 256, 56, 56]             512\n",
      "            ReLU-424          [-1, 256, 56, 56]               0\n",
      "          Conv2d-425          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-426          [-1, 256, 56, 56]             512\n",
      "            ReLU-427          [-1, 256, 56, 56]               0\n",
      "          Conv2d-428         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-429         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-430         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-431         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-432          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-433          [-1, 256, 56, 56]             512\n",
      "            ReLU-434          [-1, 256, 56, 56]               0\n",
      "          Conv2d-435          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-436          [-1, 256, 56, 56]             512\n",
      "            ReLU-437          [-1, 256, 56, 56]               0\n",
      "          Conv2d-438         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-439         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-440         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-441         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-442          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-443          [-1, 256, 56, 56]             512\n",
      "            ReLU-444          [-1, 256, 56, 56]               0\n",
      "          Conv2d-445          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-446          [-1, 256, 56, 56]             512\n",
      "            ReLU-447          [-1, 256, 56, 56]               0\n",
      "          Conv2d-448         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-449         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-450         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-451         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-452          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-453          [-1, 256, 56, 56]             512\n",
      "            ReLU-454          [-1, 256, 56, 56]               0\n",
      "          Conv2d-455          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-456          [-1, 256, 56, 56]             512\n",
      "            ReLU-457          [-1, 256, 56, 56]               0\n",
      "          Conv2d-458         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-459         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-460         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-461         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-462          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-463          [-1, 256, 56, 56]             512\n",
      "            ReLU-464          [-1, 256, 56, 56]               0\n",
      "          Conv2d-465          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-466          [-1, 256, 56, 56]             512\n",
      "            ReLU-467          [-1, 256, 56, 56]               0\n",
      "          Conv2d-468         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-469         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-470         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-471         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-472          [-1, 256, 56, 56]         262,400\n",
      "     BatchNorm2d-473          [-1, 256, 56, 56]             512\n",
      "            ReLU-474          [-1, 256, 56, 56]               0\n",
      "          Conv2d-475          [-1, 256, 56, 56]         590,080\n",
      "     BatchNorm2d-476          [-1, 256, 56, 56]             512\n",
      "            ReLU-477          [-1, 256, 56, 56]               0\n",
      "          Conv2d-478         [-1, 1024, 56, 56]         263,168\n",
      "      BottleNeck-479         [-1, 1024, 56, 56]               0\n",
      "     BatchNorm2d-480         [-1, 1024, 56, 56]           2,048\n",
      "            ReLU-481         [-1, 1024, 56, 56]               0\n",
      "          Conv2d-482          [-1, 512, 28, 28]         524,800\n",
      "     BatchNorm2d-483          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-484          [-1, 512, 28, 28]               0\n",
      "          Conv2d-485          [-1, 512, 28, 28]       2,359,808\n",
      "     BatchNorm2d-486          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-487          [-1, 512, 28, 28]               0\n",
      "          Conv2d-488         [-1, 2048, 28, 28]       1,050,624\n",
      "          Conv2d-489         [-1, 2048, 28, 28]       2,099,200\n",
      "     BatchNorm2d-490         [-1, 2048, 28, 28]           4,096\n",
      "      BottleNeck-491         [-1, 2048, 28, 28]               0\n",
      "     BatchNorm2d-492         [-1, 2048, 28, 28]           4,096\n",
      "            ReLU-493         [-1, 2048, 28, 28]               0\n",
      "          Conv2d-494          [-1, 512, 28, 28]       1,049,088\n",
      "     BatchNorm2d-495          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-496          [-1, 512, 28, 28]               0\n",
      "          Conv2d-497          [-1, 512, 28, 28]       2,359,808\n",
      "     BatchNorm2d-498          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-499          [-1, 512, 28, 28]               0\n",
      "          Conv2d-500         [-1, 2048, 28, 28]       1,050,624\n",
      "      BottleNeck-501         [-1, 2048, 28, 28]               0\n",
      "     BatchNorm2d-502         [-1, 2048, 28, 28]           4,096\n",
      "            ReLU-503         [-1, 2048, 28, 28]               0\n",
      "          Conv2d-504          [-1, 512, 28, 28]       1,049,088\n",
      "     BatchNorm2d-505          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-506          [-1, 512, 28, 28]               0\n",
      "          Conv2d-507          [-1, 512, 28, 28]       2,359,808\n",
      "     BatchNorm2d-508          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-509          [-1, 512, 28, 28]               0\n",
      "          Conv2d-510         [-1, 2048, 28, 28]       1,050,624\n",
      "      BottleNeck-511         [-1, 2048, 28, 28]               0\n",
      "     BatchNorm2d-512         [-1, 2048, 28, 28]           4,096\n",
      "            ReLU-513         [-1, 2048, 28, 28]               0\n",
      "AdaptiveAvgPool2d-514           [-1, 2048, 1, 1]               0\n",
      "          Linear-515                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 60,260,968\n",
      "Trainable params: 60,260,968\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 9316.15\n",
      "Params size (MB): 229.88\n",
      "Estimated Total Size (MB): 9546.60\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(preresnet152, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type (var_name):depth-idx)             Input Shape          Kernel Shape         Output Shape         Param %\n",
       "=============================================================================================================================\n",
       "PreActResNet (PreActResNet)                   [1, 3, 224, 224]     --                   [1, 1000]                 --\n",
       "├─Sequential (conv1): 1-1                     [1, 3, 224, 224]     --                   [1, 64, 224, 224]         --\n",
       "│    └─Conv2d (0): 2-1                        [1, 3, 224, 224]     [3, 3]               [1, 64, 224, 224]      0.00%\n",
       "│    └─BatchNorm2d (1): 2-2                   [1, 64, 224, 224]    --                   [1, 64, 224, 224]      0.00%\n",
       "│    └─ReLU (2): 2-3                          [1, 64, 224, 224]    --                   [1, 64, 224, 224]         --\n",
       "├─Sequential (layer2): 1-2                    [1, 64, 224, 224]    --                   [1, 256, 224, 224]        --\n",
       "│    └─BottleNeck (0): 2-4                    [1, 64, 224, 224]    --                   [1, 256, 224, 224]        --\n",
       "│    │    └─Sequential (residual): 3-1        [1, 64, 224, 224]    --                   [1, 256, 224, 224]        --\n",
       "│    │    │    └─BatchNorm2d (0): 4-1         [1, 64, 224, 224]    --                   [1, 64, 224, 224]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-2                [1, 64, 224, 224]    --                   [1, 64, 224, 224]         --\n",
       "│    │    │    └─Conv2d (2): 4-3              [1, 64, 224, 224]    [1, 1]               [1, 64, 224, 224]      0.01%\n",
       "│    │    │    └─BatchNorm2d (3): 4-4         [1, 64, 224, 224]    --                   [1, 64, 224, 224]      0.00%\n",
       "│    │    │    └─ReLU (4): 4-5                [1, 64, 224, 224]    --                   [1, 64, 224, 224]         --\n",
       "│    │    │    └─Conv2d (5): 4-6              [1, 64, 224, 224]    [3, 3]               [1, 64, 224, 224]      0.06%\n",
       "│    │    │    └─BatchNorm2d (6): 4-7         [1, 64, 224, 224]    --                   [1, 64, 224, 224]      0.00%\n",
       "│    │    │    └─ReLU (7): 4-8                [1, 64, 224, 224]    --                   [1, 64, 224, 224]         --\n",
       "│    │    │    └─Conv2d (8): 4-9              [1, 64, 224, 224]    [1, 1]               [1, 256, 224, 224]     0.03%\n",
       "│    │    └─Sequential (downsample): 3-2      [1, 64, 224, 224]    --                   [1, 256, 224, 224]        --\n",
       "│    │    │    └─Conv2d (0): 4-10             [1, 64, 224, 224]    [1, 1]               [1, 256, 224, 224]     0.03%\n",
       "│    │    │    └─BatchNorm2d (1): 4-11        [1, 256, 224, 224]   --                   [1, 256, 224, 224]     0.00%\n",
       "│    └─BottleNeck (1): 2-5                    [1, 256, 224, 224]   --                   [1, 256, 224, 224]        --\n",
       "│    │    └─Sequential (residual): 3-3        [1, 256, 224, 224]   --                   [1, 256, 224, 224]        --\n",
       "│    │    │    └─BatchNorm2d (0): 4-12        [1, 256, 224, 224]   --                   [1, 256, 224, 224]     0.00%\n",
       "│    │    │    └─ReLU (1): 4-13               [1, 256, 224, 224]   --                   [1, 256, 224, 224]        --\n",
       "│    │    │    └─Conv2d (2): 4-14             [1, 256, 224, 224]   [1, 1]               [1, 64, 224, 224]      0.03%\n",
       "│    │    │    └─BatchNorm2d (3): 4-15        [1, 64, 224, 224]    --                   [1, 64, 224, 224]      0.00%\n",
       "│    │    │    └─ReLU (4): 4-16               [1, 64, 224, 224]    --                   [1, 64, 224, 224]         --\n",
       "│    │    │    └─Conv2d (5): 4-17             [1, 64, 224, 224]    [3, 3]               [1, 64, 224, 224]      0.06%\n",
       "│    │    │    └─BatchNorm2d (6): 4-18        [1, 64, 224, 224]    --                   [1, 64, 224, 224]      0.00%\n",
       "│    │    │    └─ReLU (7): 4-19               [1, 64, 224, 224]    --                   [1, 64, 224, 224]         --\n",
       "│    │    │    └─Conv2d (8): 4-20             [1, 64, 224, 224]    [1, 1]               [1, 256, 224, 224]     0.03%\n",
       "│    └─BottleNeck (2): 2-6                    [1, 256, 224, 224]   --                   [1, 256, 224, 224]        --\n",
       "│    │    └─Sequential (residual): 3-4        [1, 256, 224, 224]   --                   [1, 256, 224, 224]        --\n",
       "│    │    │    └─BatchNorm2d (0): 4-21        [1, 256, 224, 224]   --                   [1, 256, 224, 224]     0.00%\n",
       "│    │    │    └─ReLU (1): 4-22               [1, 256, 224, 224]   --                   [1, 256, 224, 224]        --\n",
       "│    │    │    └─Conv2d (2): 4-23             [1, 256, 224, 224]   [1, 1]               [1, 64, 224, 224]      0.03%\n",
       "│    │    │    └─BatchNorm2d (3): 4-24        [1, 64, 224, 224]    --                   [1, 64, 224, 224]      0.00%\n",
       "│    │    │    └─ReLU (4): 4-25               [1, 64, 224, 224]    --                   [1, 64, 224, 224]         --\n",
       "│    │    │    └─Conv2d (5): 4-26             [1, 64, 224, 224]    [3, 3]               [1, 64, 224, 224]      0.06%\n",
       "│    │    │    └─BatchNorm2d (6): 4-27        [1, 64, 224, 224]    --                   [1, 64, 224, 224]      0.00%\n",
       "│    │    │    └─ReLU (7): 4-28               [1, 64, 224, 224]    --                   [1, 64, 224, 224]         --\n",
       "│    │    │    └─Conv2d (8): 4-29             [1, 64, 224, 224]    [1, 1]               [1, 256, 224, 224]     0.03%\n",
       "├─Sequential (layer3): 1-3                    [1, 256, 224, 224]   --                   [1, 512, 112, 112]        --\n",
       "│    └─BottleNeck (0): 2-7                    [1, 256, 224, 224]   --                   [1, 512, 112, 112]        --\n",
       "│    │    └─Sequential (residual): 3-5        [1, 256, 224, 224]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─BatchNorm2d (0): 4-30        [1, 256, 224, 224]   --                   [1, 256, 224, 224]     0.00%\n",
       "│    │    │    └─ReLU (1): 4-31               [1, 256, 224, 224]   --                   [1, 256, 224, 224]        --\n",
       "│    │    │    └─Conv2d (2): 4-32             [1, 256, 224, 224]   [1, 1]               [1, 128, 112, 112]     0.05%\n",
       "│    │    │    └─BatchNorm2d (3): 4-33        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (4): 4-34               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (5): 4-35             [1, 128, 112, 112]   [3, 3]               [1, 128, 112, 112]     0.24%\n",
       "│    │    │    └─BatchNorm2d (6): 4-36        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (7): 4-37               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (8): 4-38             [1, 128, 112, 112]   [1, 1]               [1, 512, 112, 112]     0.11%\n",
       "│    │    └─Sequential (downsample): 3-6      [1, 256, 224, 224]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─Conv2d (0): 4-39             [1, 256, 224, 224]   [1, 1]               [1, 512, 112, 112]     0.22%\n",
       "│    │    │    └─BatchNorm2d (1): 4-40        [1, 512, 112, 112]   --                   [1, 512, 112, 112]     0.00%\n",
       "│    └─BottleNeck (1): 2-8                    [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    └─Sequential (residual): 3-7        [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─BatchNorm2d (0): 4-41        [1, 512, 112, 112]   --                   [1, 512, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (1): 4-42               [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─Conv2d (2): 4-43             [1, 512, 112, 112]   [1, 1]               [1, 128, 112, 112]     0.11%\n",
       "│    │    │    └─BatchNorm2d (3): 4-44        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (4): 4-45               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (5): 4-46             [1, 128, 112, 112]   [3, 3]               [1, 128, 112, 112]     0.24%\n",
       "│    │    │    └─BatchNorm2d (6): 4-47        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (7): 4-48               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (8): 4-49             [1, 128, 112, 112]   [1, 1]               [1, 512, 112, 112]     0.11%\n",
       "│    └─BottleNeck (2): 2-9                    [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    └─Sequential (residual): 3-8        [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─BatchNorm2d (0): 4-50        [1, 512, 112, 112]   --                   [1, 512, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (1): 4-51               [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─Conv2d (2): 4-52             [1, 512, 112, 112]   [1, 1]               [1, 128, 112, 112]     0.11%\n",
       "│    │    │    └─BatchNorm2d (3): 4-53        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (4): 4-54               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (5): 4-55             [1, 128, 112, 112]   [3, 3]               [1, 128, 112, 112]     0.24%\n",
       "│    │    │    └─BatchNorm2d (6): 4-56        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (7): 4-57               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (8): 4-58             [1, 128, 112, 112]   [1, 1]               [1, 512, 112, 112]     0.11%\n",
       "│    └─BottleNeck (3): 2-10                   [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    └─Sequential (residual): 3-9        [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─BatchNorm2d (0): 4-59        [1, 512, 112, 112]   --                   [1, 512, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (1): 4-60               [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─Conv2d (2): 4-61             [1, 512, 112, 112]   [1, 1]               [1, 128, 112, 112]     0.11%\n",
       "│    │    │    └─BatchNorm2d (3): 4-62        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (4): 4-63               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (5): 4-64             [1, 128, 112, 112]   [3, 3]               [1, 128, 112, 112]     0.24%\n",
       "│    │    │    └─BatchNorm2d (6): 4-65        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (7): 4-66               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (8): 4-67             [1, 128, 112, 112]   [1, 1]               [1, 512, 112, 112]     0.11%\n",
       "│    └─BottleNeck (4): 2-11                   [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    └─Sequential (residual): 3-10       [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─BatchNorm2d (0): 4-68        [1, 512, 112, 112]   --                   [1, 512, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (1): 4-69               [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─Conv2d (2): 4-70             [1, 512, 112, 112]   [1, 1]               [1, 128, 112, 112]     0.11%\n",
       "│    │    │    └─BatchNorm2d (3): 4-71        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (4): 4-72               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (5): 4-73             [1, 128, 112, 112]   [3, 3]               [1, 128, 112, 112]     0.24%\n",
       "│    │    │    └─BatchNorm2d (6): 4-74        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (7): 4-75               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (8): 4-76             [1, 128, 112, 112]   [1, 1]               [1, 512, 112, 112]     0.11%\n",
       "│    └─BottleNeck (5): 2-12                   [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    └─Sequential (residual): 3-11       [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─BatchNorm2d (0): 4-77        [1, 512, 112, 112]   --                   [1, 512, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (1): 4-78               [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─Conv2d (2): 4-79             [1, 512, 112, 112]   [1, 1]               [1, 128, 112, 112]     0.11%\n",
       "│    │    │    └─BatchNorm2d (3): 4-80        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (4): 4-81               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (5): 4-82             [1, 128, 112, 112]   [3, 3]               [1, 128, 112, 112]     0.24%\n",
       "│    │    │    └─BatchNorm2d (6): 4-83        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (7): 4-84               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (8): 4-85             [1, 128, 112, 112]   [1, 1]               [1, 512, 112, 112]     0.11%\n",
       "│    └─BottleNeck (6): 2-13                   [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    └─Sequential (residual): 3-12       [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─BatchNorm2d (0): 4-86        [1, 512, 112, 112]   --                   [1, 512, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (1): 4-87               [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─Conv2d (2): 4-88             [1, 512, 112, 112]   [1, 1]               [1, 128, 112, 112]     0.11%\n",
       "│    │    │    └─BatchNorm2d (3): 4-89        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (4): 4-90               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (5): 4-91             [1, 128, 112, 112]   [3, 3]               [1, 128, 112, 112]     0.24%\n",
       "│    │    │    └─BatchNorm2d (6): 4-92        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (7): 4-93               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (8): 4-94             [1, 128, 112, 112]   [1, 1]               [1, 512, 112, 112]     0.11%\n",
       "│    └─BottleNeck (7): 2-14                   [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    └─Sequential (residual): 3-13       [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─BatchNorm2d (0): 4-95        [1, 512, 112, 112]   --                   [1, 512, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (1): 4-96               [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─Conv2d (2): 4-97             [1, 512, 112, 112]   [1, 1]               [1, 128, 112, 112]     0.11%\n",
       "│    │    │    └─BatchNorm2d (3): 4-98        [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (4): 4-99               [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (5): 4-100            [1, 128, 112, 112]   [3, 3]               [1, 128, 112, 112]     0.24%\n",
       "│    │    │    └─BatchNorm2d (6): 4-101       [1, 128, 112, 112]   --                   [1, 128, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (7): 4-102              [1, 128, 112, 112]   --                   [1, 128, 112, 112]        --\n",
       "│    │    │    └─Conv2d (8): 4-103            [1, 128, 112, 112]   [1, 1]               [1, 512, 112, 112]     0.11%\n",
       "├─Sequential (layer4): 1-4                    [1, 512, 112, 112]   --                   [1, 1024, 56, 56]         --\n",
       "│    └─BottleNeck (0): 2-15                   [1, 512, 112, 112]   --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-14       [1, 512, 112, 112]   --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-104       [1, 512, 112, 112]   --                   [1, 512, 112, 112]     0.00%\n",
       "│    │    │    └─ReLU (1): 4-105              [1, 512, 112, 112]   --                   [1, 512, 112, 112]        --\n",
       "│    │    │    └─Conv2d (2): 4-106            [1, 512, 112, 112]   [1, 1]               [1, 256, 56, 56]       0.22%\n",
       "│    │    │    └─BatchNorm2d (3): 4-107       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-108              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-109            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-110       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-111              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-112            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    │    └─Sequential (downsample): 3-15     [1, 512, 112, 112]   --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (0): 4-113            [1, 512, 112, 112]   [1, 1]               [1, 1024, 56, 56]      0.87%\n",
       "│    │    │    └─BatchNorm2d (1): 4-114       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    └─BottleNeck (1): 2-16                   [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-16       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-115       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-116              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-117            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-118       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-119              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-120            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-121       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-122              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-123            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (2): 2-17                   [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-17       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-124       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-125              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-126            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-127       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-128              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-129            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-130       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-131              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-132            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (3): 2-18                   [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-18       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-133       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-134              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-135            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-136       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-137              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-138            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-139       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-140              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-141            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (4): 2-19                   [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-19       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-142       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-143              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-144            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-145       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-146              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-147            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-148       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-149              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-150            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (5): 2-20                   [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-20       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-151       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-152              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-153            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-154       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-155              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-156            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-157       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-158              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-159            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (6): 2-21                   [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-21       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-160       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-161              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-162            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-163       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-164              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-165            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-166       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-167              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-168            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (7): 2-22                   [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-22       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-169       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-170              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-171            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-172       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-173              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-174            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-175       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-176              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-177            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (8): 2-23                   [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-23       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-178       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-179              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-180            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-181       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-182              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-183            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-184       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-185              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-186            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (9): 2-24                   [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-24       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-187       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-188              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-189            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-190       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-191              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-192            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-193       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-194              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-195            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (10): 2-25                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-25       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-196       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-197              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-198            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-199       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-200              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-201            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-202       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-203              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-204            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (11): 2-26                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-26       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-205       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-206              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-207            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-208       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-209              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-210            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-211       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-212              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-213            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (12): 2-27                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-27       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-214       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-215              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-216            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-217       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-218              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-219            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-220       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-221              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-222            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (13): 2-28                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-28       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-223       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-224              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-225            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-226       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-227              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-228            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-229       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-230              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-231            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (14): 2-29                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-29       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-232       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-233              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-234            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-235       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-236              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-237            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-238       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-239              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-240            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (15): 2-30                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-30       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-241       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-242              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-243            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-244       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-245              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-246            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-247       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-248              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-249            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (16): 2-31                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-31       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-250       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-251              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-252            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-253       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-254              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-255            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-256       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-257              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-258            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (17): 2-32                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-32       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-259       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-260              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-261            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-262       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-263              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-264            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-265       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-266              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-267            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (18): 2-33                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-33       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-268       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-269              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-270            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-271       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-272              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-273            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-274       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-275              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-276            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (19): 2-34                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-34       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-277       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-278              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-279            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-280       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-281              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-282            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-283       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-284              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-285            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (20): 2-35                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-35       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-286       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-287              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-288            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-289       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-290              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-291            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-292       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-293              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-294            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (21): 2-36                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-36       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-295       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-296              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-297            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-298       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-299              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-300            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-301       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-302              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-303            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (22): 2-37                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-37       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-304       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-305              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-306            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-307       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-308              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-309            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-310       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-311              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-312            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (23): 2-38                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-38       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-313       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-314              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-315            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-316       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-317              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-318            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-319       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-320              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-321            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (24): 2-39                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-39       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-322       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-323              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-324            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-325       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-326              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-327            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-328       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-329              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-330            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (25): 2-40                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-40       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-331       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-332              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-333            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-334       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-335              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-336            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-337       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-338              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-339            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (26): 2-41                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-41       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-340       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-341              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-342            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-343       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-344              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-345            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-346       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-347              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-348            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (27): 2-42                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-42       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-349       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-350              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-351            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-352       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-353              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-354            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-355       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-356              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-357            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (28): 2-43                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-43       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-358       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-359              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-360            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-361       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-362              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-363            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-364       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-365              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-366            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (29): 2-44                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-44       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-367       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-368              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-369            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-370       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-371              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-372            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-373       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-374              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-375            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (30): 2-45                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-45       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-376       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-377              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-378            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-379       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-380              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-381            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-382       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-383              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-384            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (31): 2-46                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-46       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-385       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-386              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-387            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-388       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-389              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-390            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-391       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-392              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-393            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (32): 2-47                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-47       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-394       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-395              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-396            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-397       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-398              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-399            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-400       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-401              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-402            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (33): 2-48                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-48       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-403       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-404              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-405            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-406       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-407              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-408            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-409       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-410              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-411            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (34): 2-49                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-49       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-412       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-413              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-414            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-415       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-416              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-417            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-418       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-419              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-420            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "│    └─BottleNeck (35): 2-50                  [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    └─Sequential (residual): 3-50       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-421       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-422              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-423            [1, 1024, 56, 56]    [1, 1]               [1, 256, 56, 56]       0.44%\n",
       "│    │    │    └─BatchNorm2d (3): 4-424       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-425              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (5): 4-426            [1, 256, 56, 56]     [3, 3]               [1, 256, 56, 56]       0.98%\n",
       "│    │    │    └─BatchNorm2d (6): 4-427       [1, 256, 56, 56]     --                   [1, 256, 56, 56]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-428              [1, 256, 56, 56]     --                   [1, 256, 56, 56]          --\n",
       "│    │    │    └─Conv2d (8): 4-429            [1, 256, 56, 56]     [1, 1]               [1, 1024, 56, 56]      0.44%\n",
       "├─Sequential (layer5): 1-5                    [1, 1024, 56, 56]    --                   [1, 2048, 28, 28]         --\n",
       "│    └─BottleNeck (0): 2-51                   [1, 1024, 56, 56]    --                   [1, 2048, 28, 28]         --\n",
       "│    │    └─Sequential (residual): 3-51       [1, 1024, 56, 56]    --                   [1, 2048, 28, 28]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-430       [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]      0.00%\n",
       "│    │    │    └─ReLU (1): 4-431              [1, 1024, 56, 56]    --                   [1, 1024, 56, 56]         --\n",
       "│    │    │    └─Conv2d (2): 4-432            [1, 1024, 56, 56]    [1, 1]               [1, 512, 28, 28]       0.87%\n",
       "│    │    │    └─BatchNorm2d (3): 4-433       [1, 512, 28, 28]     --                   [1, 512, 28, 28]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-434              [1, 512, 28, 28]     --                   [1, 512, 28, 28]          --\n",
       "│    │    │    └─Conv2d (5): 4-435            [1, 512, 28, 28]     [3, 3]               [1, 512, 28, 28]       3.92%\n",
       "│    │    │    └─BatchNorm2d (6): 4-436       [1, 512, 28, 28]     --                   [1, 512, 28, 28]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-437              [1, 512, 28, 28]     --                   [1, 512, 28, 28]          --\n",
       "│    │    │    └─Conv2d (8): 4-438            [1, 512, 28, 28]     [1, 1]               [1, 2048, 28, 28]      1.74%\n",
       "│    │    └─Sequential (downsample): 3-52     [1, 1024, 56, 56]    --                   [1, 2048, 28, 28]         --\n",
       "│    │    │    └─Conv2d (0): 4-439            [1, 1024, 56, 56]    [1, 1]               [1, 2048, 28, 28]      3.48%\n",
       "│    │    │    └─BatchNorm2d (1): 4-440       [1, 2048, 28, 28]    --                   [1, 2048, 28, 28]      0.01%\n",
       "│    └─BottleNeck (1): 2-52                   [1, 2048, 28, 28]    --                   [1, 2048, 28, 28]         --\n",
       "│    │    └─Sequential (residual): 3-53       [1, 2048, 28, 28]    --                   [1, 2048, 28, 28]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-441       [1, 2048, 28, 28]    --                   [1, 2048, 28, 28]      0.01%\n",
       "│    │    │    └─ReLU (1): 4-442              [1, 2048, 28, 28]    --                   [1, 2048, 28, 28]         --\n",
       "│    │    │    └─Conv2d (2): 4-443            [1, 2048, 28, 28]    [1, 1]               [1, 512, 28, 28]       1.74%\n",
       "│    │    │    └─BatchNorm2d (3): 4-444       [1, 512, 28, 28]     --                   [1, 512, 28, 28]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-445              [1, 512, 28, 28]     --                   [1, 512, 28, 28]          --\n",
       "│    │    │    └─Conv2d (5): 4-446            [1, 512, 28, 28]     [3, 3]               [1, 512, 28, 28]       3.92%\n",
       "│    │    │    └─BatchNorm2d (6): 4-447       [1, 512, 28, 28]     --                   [1, 512, 28, 28]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-448              [1, 512, 28, 28]     --                   [1, 512, 28, 28]          --\n",
       "│    │    │    └─Conv2d (8): 4-449            [1, 512, 28, 28]     [1, 1]               [1, 2048, 28, 28]      1.74%\n",
       "│    └─BottleNeck (2): 2-53                   [1, 2048, 28, 28]    --                   [1, 2048, 28, 28]         --\n",
       "│    │    └─Sequential (residual): 3-54       [1, 2048, 28, 28]    --                   [1, 2048, 28, 28]         --\n",
       "│    │    │    └─BatchNorm2d (0): 4-450       [1, 2048, 28, 28]    --                   [1, 2048, 28, 28]      0.01%\n",
       "│    │    │    └─ReLU (1): 4-451              [1, 2048, 28, 28]    --                   [1, 2048, 28, 28]         --\n",
       "│    │    │    └─Conv2d (2): 4-452            [1, 2048, 28, 28]    [1, 1]               [1, 512, 28, 28]       1.74%\n",
       "│    │    │    └─BatchNorm2d (3): 4-453       [1, 512, 28, 28]     --                   [1, 512, 28, 28]       0.00%\n",
       "│    │    │    └─ReLU (4): 4-454              [1, 512, 28, 28]     --                   [1, 512, 28, 28]          --\n",
       "│    │    │    └─Conv2d (5): 4-455            [1, 512, 28, 28]     [3, 3]               [1, 512, 28, 28]       3.92%\n",
       "│    │    │    └─BatchNorm2d (6): 4-456       [1, 512, 28, 28]     --                   [1, 512, 28, 28]       0.00%\n",
       "│    │    │    └─ReLU (7): 4-457              [1, 512, 28, 28]     --                   [1, 512, 28, 28]          --\n",
       "│    │    │    └─Conv2d (8): 4-458            [1, 512, 28, 28]     [1, 1]               [1, 2048, 28, 28]      1.74%\n",
       "├─Sequential (last_act): 1-6                  [1, 2048, 28, 28]    --                   [1, 2048, 28, 28]         --\n",
       "│    └─BatchNorm2d (0): 2-54                  [1, 2048, 28, 28]    --                   [1, 2048, 28, 28]      0.01%\n",
       "│    └─ReLU (1): 2-55                         [1, 2048, 28, 28]    --                   [1, 2048, 28, 28]         --\n",
       "├─AdaptiveAvgPool2d (avg_pool): 1-7           [1, 2048, 28, 28]    --                   [1, 2048, 1, 1]           --\n",
       "├─Linear (linear): 1-8                        [1, 2048]            --                   [1, 1000]              3.40%\n",
       "=============================================================================================================================\n",
       "Total params: 60,260,968\n",
       "Trainable params: 60,260,968\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 179.03\n",
       "=============================================================================================================================\n",
       "Input size (MB): 0.60\n",
       "Forward/backward pass size (MB): 5510.54\n",
       "Params size (MB): 241.04\n",
       "Estimated Total Size (MB): 5752.18\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(preresnet152, input_size=(1, 3, 224, 224), col_width=20, depth=200, row_settings=[\"depth\", \"var_names\"], col_names=[\"input_size\", \"kernel_size\", \"output_size\", \"params_percent\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "for_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
