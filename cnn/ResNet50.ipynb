{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Paper: [2015.12.10] Deep Residual Learning for Image Recognition\n",
    "- https://arxiv.org/abs/1512.03385"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Package load]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Model: ResNet50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution, no padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample    # stride = 2일 때 skip과 identity size 맞춰주기 위해 사용\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x) # 3x3 stride = 받아온 stride\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out) # 3x3 stride = 1\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "            '''처음 stride = 2, x = 3x64x64로 가정\n",
    "            : stride 2라서 feature 수 줄어서 identity도 줄이기 위해 만든다.\n",
    "            identity = 3x64x64, out = 3x32x32 (d/t stride = 2)\n",
    "            이후 쭉 지나가다 down sample 없다고 하면 3x64x64랑 3x32x32랑 덧셈 불가능해짐'''\n",
    "\n",
    "        out += identity         # out을 identity와 더해주기\n",
    "        out = self.relu(out)    # 이후 return\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv1x1(inplanes, planes) #conv1x1(64,64)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)#conv3x3(64,64)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = conv1x1(planes, planes * self.expansion) #conv1x1(64,256) channel 뻥튀기 위해 expansion이 되어 있다.\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x) # 1x1 stride = 1\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out) # 3x3 stride = stride \n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out) # 1x1 planes. planes*self.expansion, stride = 1\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "            # 마찬가지 stride 달라지면 downsample 고려해야 함\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    # model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs) #resnet 50 \n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        '''block은 bottleneck, layer는 list로'''\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.inplanes = 64\n",
    "\n",
    "        # input: 3x224x224       \n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # self.conv1(input) -> output=64x112x112\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # input: 64x112x112\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        # output: 64x56x56\n",
    "        \n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])    #layers[0]=3\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2) #layers[1]=4\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)  #layers[2]=6\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)  #layers[3]=3\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():    # weight 초기화\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "            # 논문에 근거가 나와 있음\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "    \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        # self.layer1 = self._make_layer(Bottleneck, 64, layers[0]'''3''')\n",
    "            # block = bottleneck, planes = 64, blocks = layers[0]인 3, stirde = 1\n",
    "        # self.inplanes의 경우 이제 256이 들어가있음\n",
    "        # self.layer2 = self._make_layer(Bottleneck, 128, layers[0]'''4''', stride = 2)\n",
    "        downsample = None\n",
    "        \n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:   \n",
    "                            # inplanes = 64 != 64 * 4 (bottleneck의 expansion)\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride), #conv1x1(64, 256, 1)\n",
    "                nn.BatchNorm2d(planes * block.expansion), #batchnrom2d(256)\n",
    "            )\n",
    "            # 원래 feature 수 맞추려고 쓰는데 여기서는 channel을 맞추는 용도로 사용함\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "            # layers.append(Bottleneck(64, 64, 1, downsample))\n",
    "        self.inplanes = planes * block.expansion #self.inplanes = 64 * 4\n",
    "        \n",
    "        for _ in range(1, blocks): \n",
    "            layers.append(block(self.inplanes, planes)) # * 3\n",
    "            # blocks가 3이면 실제로는 2번만 돈다\n",
    "        return nn.Sequential(*layers)\n",
    "        '''self.layer1 = [\n",
    "            layers.append(Bottleneck(64, 64, 1, downsample))\n",
    "            Bottleneck(256, 64)\n",
    "            Bottleneck(256, 64)\n",
    "        ]\n",
    "        self.layer2 = [\n",
    "            layers.append(Bottleneck(256, 128, 2, downsample))\n",
    "            Bottleneck(512, 128)\n",
    "            Bottleneck(512, 128)\n",
    "            Bottleneck(512, 128)\n",
    "        ]'''\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x) # FC layer 대신 1x1 pooling으로 묶어버리기\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = ResNet(Bottleneck, [3, 4, 6, 3], 4, True).to(device) \n",
    "# 1(conv1) + 9(layer1) + 12(layer2) + 18(layer3) + 9(layer4) +1(fc)= ResNet50\n",
    "# OCT classification에서 class 4개이므로 4를 대입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                    [-1, 4]           8,196\n",
      "================================================================\n",
      "Total params: 23,516,228\n",
      "Trainable params: 23,516,228\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 89.71\n",
      "Estimated Total Size (MB): 376.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(resnet50, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Model: ResNet50 Transfer learning]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransferResNet(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(TransferResNet, self).__init__()\n",
    "        self.ResNet50 = torchvision.models.resnet50(pretrained=True)\n",
    "        self.ResNet50.fc = nn.Linear(2048, 4)        # Final layer input = 512, Final layer output = 4 (num of classes) (original: 1000)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.ResNet50(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniconda3\\envs\\for_learning\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\miniconda3\\envs\\for_learning\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet50_transfer = TransferResNet().to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransferResNet(\n",
       "  (ResNet50): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet50_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                    [-1, 4]           8,196\n",
      "          ResNet-175                    [-1, 4]               0\n",
      "================================================================\n",
      "Total params: 23,516,228\n",
      "Trainable params: 23,516,228\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.55\n",
      "Params size (MB): 89.71\n",
      "Estimated Total Size (MB): 376.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(resnet50_transfer, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count:1, ResNet50.conv1.weight True\n",
      "count:2, ResNet50.bn1.weight True\n",
      "count:3, ResNet50.bn1.bias True\n",
      "count:4, ResNet50.layer1.0.conv1.weight True\n",
      "count:5, ResNet50.layer1.0.bn1.weight True\n",
      "count:6, ResNet50.layer1.0.bn1.bias True\n",
      "count:7, ResNet50.layer1.0.conv2.weight True\n",
      "count:8, ResNet50.layer1.0.bn2.weight True\n",
      "count:9, ResNet50.layer1.0.bn2.bias True\n",
      "count:10, ResNet50.layer1.0.conv3.weight True\n",
      "count:11, ResNet50.layer1.0.bn3.weight True\n",
      "count:12, ResNet50.layer1.0.bn3.bias True\n",
      "count:13, ResNet50.layer1.0.downsample.0.weight True\n",
      "count:14, ResNet50.layer1.0.downsample.1.weight True\n",
      "count:15, ResNet50.layer1.0.downsample.1.bias True\n",
      "count:16, ResNet50.layer1.1.conv1.weight True\n",
      "count:17, ResNet50.layer1.1.bn1.weight True\n",
      "count:18, ResNet50.layer1.1.bn1.bias True\n",
      "count:19, ResNet50.layer1.1.conv2.weight True\n",
      "count:20, ResNet50.layer1.1.bn2.weight True\n",
      "count:21, ResNet50.layer1.1.bn2.bias True\n",
      "count:22, ResNet50.layer1.1.conv3.weight True\n",
      "count:23, ResNet50.layer1.1.bn3.weight True\n",
      "count:24, ResNet50.layer1.1.bn3.bias True\n",
      "count:25, ResNet50.layer1.2.conv1.weight True\n",
      "count:26, ResNet50.layer1.2.bn1.weight True\n",
      "count:27, ResNet50.layer1.2.bn1.bias True\n",
      "count:28, ResNet50.layer1.2.conv2.weight True\n",
      "count:29, ResNet50.layer1.2.bn2.weight True\n",
      "count:30, ResNet50.layer1.2.bn2.bias True\n",
      "count:31, ResNet50.layer1.2.conv3.weight True\n",
      "count:32, ResNet50.layer1.2.bn3.weight True\n",
      "count:33, ResNet50.layer1.2.bn3.bias True\n",
      "count:34, ResNet50.layer2.0.conv1.weight True\n",
      "count:35, ResNet50.layer2.0.bn1.weight True\n",
      "count:36, ResNet50.layer2.0.bn1.bias True\n",
      "count:37, ResNet50.layer2.0.conv2.weight True\n",
      "count:38, ResNet50.layer2.0.bn2.weight True\n",
      "count:39, ResNet50.layer2.0.bn2.bias True\n",
      "count:40, ResNet50.layer2.0.conv3.weight True\n",
      "count:41, ResNet50.layer2.0.bn3.weight True\n",
      "count:42, ResNet50.layer2.0.bn3.bias True\n",
      "count:43, ResNet50.layer2.0.downsample.0.weight True\n",
      "count:44, ResNet50.layer2.0.downsample.1.weight True\n",
      "count:45, ResNet50.layer2.0.downsample.1.bias True\n",
      "count:46, ResNet50.layer2.1.conv1.weight True\n",
      "count:47, ResNet50.layer2.1.bn1.weight True\n",
      "count:48, ResNet50.layer2.1.bn1.bias True\n",
      "count:49, ResNet50.layer2.1.conv2.weight True\n",
      "count:50, ResNet50.layer2.1.bn2.weight True\n",
      "count:51, ResNet50.layer2.1.bn2.bias True\n",
      "count:52, ResNet50.layer2.1.conv3.weight True\n",
      "count:53, ResNet50.layer2.1.bn3.weight True\n",
      "count:54, ResNet50.layer2.1.bn3.bias True\n",
      "count:55, ResNet50.layer2.2.conv1.weight True\n",
      "count:56, ResNet50.layer2.2.bn1.weight True\n",
      "count:57, ResNet50.layer2.2.bn1.bias True\n",
      "count:58, ResNet50.layer2.2.conv2.weight True\n",
      "count:59, ResNet50.layer2.2.bn2.weight True\n",
      "count:60, ResNet50.layer2.2.bn2.bias True\n",
      "count:61, ResNet50.layer2.2.conv3.weight True\n",
      "count:62, ResNet50.layer2.2.bn3.weight True\n",
      "count:63, ResNet50.layer2.2.bn3.bias True\n",
      "count:64, ResNet50.layer2.3.conv1.weight True\n",
      "count:65, ResNet50.layer2.3.bn1.weight True\n",
      "count:66, ResNet50.layer2.3.bn1.bias True\n",
      "count:67, ResNet50.layer2.3.conv2.weight True\n",
      "count:68, ResNet50.layer2.3.bn2.weight True\n",
      "count:69, ResNet50.layer2.3.bn2.bias True\n",
      "count:70, ResNet50.layer2.3.conv3.weight True\n",
      "count:71, ResNet50.layer2.3.bn3.weight True\n",
      "count:72, ResNet50.layer2.3.bn3.bias True\n",
      "count:73, ResNet50.layer3.0.conv1.weight True\n",
      "count:74, ResNet50.layer3.0.bn1.weight True\n",
      "count:75, ResNet50.layer3.0.bn1.bias True\n",
      "count:76, ResNet50.layer3.0.conv2.weight True\n",
      "count:77, ResNet50.layer3.0.bn2.weight True\n",
      "count:78, ResNet50.layer3.0.bn2.bias True\n",
      "count:79, ResNet50.layer3.0.conv3.weight True\n",
      "count:80, ResNet50.layer3.0.bn3.weight True\n",
      "count:81, ResNet50.layer3.0.bn3.bias True\n",
      "count:82, ResNet50.layer3.0.downsample.0.weight True\n",
      "count:83, ResNet50.layer3.0.downsample.1.weight True\n",
      "count:84, ResNet50.layer3.0.downsample.1.bias True\n",
      "count:85, ResNet50.layer3.1.conv1.weight True\n",
      "count:86, ResNet50.layer3.1.bn1.weight True\n",
      "count:87, ResNet50.layer3.1.bn1.bias True\n",
      "count:88, ResNet50.layer3.1.conv2.weight True\n",
      "count:89, ResNet50.layer3.1.bn2.weight True\n",
      "count:90, ResNet50.layer3.1.bn2.bias True\n",
      "count:91, ResNet50.layer3.1.conv3.weight True\n",
      "count:92, ResNet50.layer3.1.bn3.weight True\n",
      "count:93, ResNet50.layer3.1.bn3.bias True\n",
      "count:94, ResNet50.layer3.2.conv1.weight True\n",
      "count:95, ResNet50.layer3.2.bn1.weight True\n",
      "count:96, ResNet50.layer3.2.bn1.bias True\n",
      "count:97, ResNet50.layer3.2.conv2.weight True\n",
      "count:98, ResNet50.layer3.2.bn2.weight True\n",
      "count:99, ResNet50.layer3.2.bn2.bias True\n",
      "count:100, ResNet50.layer3.2.conv3.weight True\n",
      "count:101, ResNet50.layer3.2.bn3.weight True\n",
      "count:102, ResNet50.layer3.2.bn3.bias True\n",
      "count:103, ResNet50.layer3.3.conv1.weight True\n",
      "count:104, ResNet50.layer3.3.bn1.weight True\n",
      "count:105, ResNet50.layer3.3.bn1.bias True\n",
      "count:106, ResNet50.layer3.3.conv2.weight True\n",
      "count:107, ResNet50.layer3.3.bn2.weight True\n",
      "count:108, ResNet50.layer3.3.bn2.bias True\n",
      "count:109, ResNet50.layer3.3.conv3.weight True\n",
      "count:110, ResNet50.layer3.3.bn3.weight True\n",
      "count:111, ResNet50.layer3.3.bn3.bias True\n",
      "count:112, ResNet50.layer3.4.conv1.weight True\n",
      "count:113, ResNet50.layer3.4.bn1.weight True\n",
      "count:114, ResNet50.layer3.4.bn1.bias True\n",
      "count:115, ResNet50.layer3.4.conv2.weight True\n",
      "count:116, ResNet50.layer3.4.bn2.weight True\n",
      "count:117, ResNet50.layer3.4.bn2.bias True\n",
      "count:118, ResNet50.layer3.4.conv3.weight True\n",
      "count:119, ResNet50.layer3.4.bn3.weight True\n",
      "count:120, ResNet50.layer3.4.bn3.bias True\n",
      "count:121, ResNet50.layer3.5.conv1.weight True\n",
      "count:122, ResNet50.layer3.5.bn1.weight True\n",
      "count:123, ResNet50.layer3.5.bn1.bias True\n",
      "count:124, ResNet50.layer3.5.conv2.weight True\n",
      "count:125, ResNet50.layer3.5.bn2.weight True\n",
      "count:126, ResNet50.layer3.5.bn2.bias True\n",
      "count:127, ResNet50.layer3.5.conv3.weight True\n",
      "count:128, ResNet50.layer3.5.bn3.weight True\n",
      "count:129, ResNet50.layer3.5.bn3.bias True\n",
      "count:130, ResNet50.layer4.0.conv1.weight True\n",
      "count:131, ResNet50.layer4.0.bn1.weight True\n",
      "count:132, ResNet50.layer4.0.bn1.bias True\n",
      "count:133, ResNet50.layer4.0.conv2.weight True\n",
      "count:134, ResNet50.layer4.0.bn2.weight True\n",
      "count:135, ResNet50.layer4.0.bn2.bias True\n",
      "count:136, ResNet50.layer4.0.conv3.weight True\n",
      "count:137, ResNet50.layer4.0.bn3.weight True\n",
      "count:138, ResNet50.layer4.0.bn3.bias True\n",
      "count:139, ResNet50.layer4.0.downsample.0.weight True\n",
      "count:140, ResNet50.layer4.0.downsample.1.weight True\n",
      "count:141, ResNet50.layer4.0.downsample.1.bias True\n",
      "count:142, ResNet50.layer4.1.conv1.weight True\n",
      "count:143, ResNet50.layer4.1.bn1.weight True\n",
      "count:144, ResNet50.layer4.1.bn1.bias True\n",
      "count:145, ResNet50.layer4.1.conv2.weight True\n",
      "count:146, ResNet50.layer4.1.bn2.weight True\n",
      "count:147, ResNet50.layer4.1.bn2.bias True\n",
      "count:148, ResNet50.layer4.1.conv3.weight True\n",
      "count:149, ResNet50.layer4.1.bn3.weight True\n",
      "count:150, ResNet50.layer4.1.bn3.bias True\n",
      "count:151, ResNet50.layer4.2.conv1.weight True\n",
      "count:152, ResNet50.layer4.2.bn1.weight True\n",
      "count:153, ResNet50.layer4.2.bn1.bias True\n",
      "count:154, ResNet50.layer4.2.conv2.weight True\n",
      "count:155, ResNet50.layer4.2.bn2.weight True\n",
      "count:156, ResNet50.layer4.2.bn2.bias True\n",
      "count:157, ResNet50.layer4.2.conv3.weight True\n",
      "count:158, ResNet50.layer4.2.bn3.weight True\n",
      "count:159, ResNet50.layer4.2.bn3.bias True\n",
      "count:160, ResNet50.fc.weight True\n",
      "count:161, ResNet50.fc.bias True\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for name, param in resnet50_transfer.named_parameters():\n",
    "    count += 1\n",
    "    print(f\"count:{count},\",name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://89douner.tistory.com/289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet50.conv1.weight False\n",
      "ResNet50.bn1.weight False\n",
      "ResNet50.bn1.bias False\n",
      "ResNet50.layer1.0.conv1.weight False\n",
      "ResNet50.layer1.0.bn1.weight False\n",
      "ResNet50.layer1.0.bn1.bias False\n",
      "ResNet50.layer1.0.conv2.weight False\n",
      "ResNet50.layer1.0.bn2.weight False\n",
      "ResNet50.layer1.0.bn2.bias False\n",
      "ResNet50.layer1.0.conv3.weight False\n",
      "ResNet50.layer1.0.bn3.weight False\n",
      "ResNet50.layer1.0.bn3.bias False\n",
      "ResNet50.layer1.0.downsample.0.weight False\n",
      "ResNet50.layer1.0.downsample.1.weight False\n",
      "ResNet50.layer1.0.downsample.1.bias False\n",
      "ResNet50.layer1.1.conv1.weight False\n",
      "ResNet50.layer1.1.bn1.weight False\n",
      "ResNet50.layer1.1.bn1.bias False\n",
      "ResNet50.layer1.1.conv2.weight False\n",
      "ResNet50.layer1.1.bn2.weight False\n",
      "ResNet50.layer1.1.bn2.bias False\n",
      "ResNet50.layer1.1.conv3.weight False\n",
      "ResNet50.layer1.1.bn3.weight False\n",
      "ResNet50.layer1.1.bn3.bias False\n",
      "ResNet50.layer1.2.conv1.weight False\n",
      "ResNet50.layer1.2.bn1.weight False\n",
      "ResNet50.layer1.2.bn1.bias False\n",
      "ResNet50.layer1.2.conv2.weight False\n",
      "ResNet50.layer1.2.bn2.weight False\n",
      "ResNet50.layer1.2.bn2.bias False\n",
      "ResNet50.layer1.2.conv3.weight False\n",
      "ResNet50.layer1.2.bn3.weight False\n",
      "ResNet50.layer1.2.bn3.bias False\n",
      "ResNet50.layer2.0.conv1.weight False\n",
      "ResNet50.layer2.0.bn1.weight False\n",
      "ResNet50.layer2.0.bn1.bias False\n",
      "ResNet50.layer2.0.conv2.weight False\n",
      "ResNet50.layer2.0.bn2.weight False\n",
      "ResNet50.layer2.0.bn2.bias False\n",
      "ResNet50.layer2.0.conv3.weight False\n",
      "ResNet50.layer2.0.bn3.weight False\n",
      "ResNet50.layer2.0.bn3.bias False\n",
      "ResNet50.layer2.0.downsample.0.weight False\n",
      "ResNet50.layer2.0.downsample.1.weight False\n",
      "ResNet50.layer2.0.downsample.1.bias False\n",
      "ResNet50.layer2.1.conv1.weight False\n",
      "ResNet50.layer2.1.bn1.weight False\n",
      "ResNet50.layer2.1.bn1.bias False\n",
      "ResNet50.layer2.1.conv2.weight False\n",
      "ResNet50.layer2.1.bn2.weight False\n",
      "ResNet50.layer2.1.bn2.bias False\n",
      "ResNet50.layer2.1.conv3.weight False\n",
      "ResNet50.layer2.1.bn3.weight False\n",
      "ResNet50.layer2.1.bn3.bias False\n",
      "ResNet50.layer2.2.conv1.weight False\n",
      "ResNet50.layer2.2.bn1.weight False\n",
      "ResNet50.layer2.2.bn1.bias False\n",
      "ResNet50.layer2.2.conv2.weight False\n",
      "ResNet50.layer2.2.bn2.weight False\n",
      "ResNet50.layer2.2.bn2.bias False\n",
      "ResNet50.layer2.2.conv3.weight False\n",
      "ResNet50.layer2.2.bn3.weight False\n",
      "ResNet50.layer2.2.bn3.bias False\n",
      "ResNet50.layer2.3.conv1.weight False\n",
      "ResNet50.layer2.3.bn1.weight False\n",
      "ResNet50.layer2.3.bn1.bias False\n",
      "ResNet50.layer2.3.conv2.weight False\n",
      "ResNet50.layer2.3.bn2.weight False\n",
      "ResNet50.layer2.3.bn2.bias False\n",
      "ResNet50.layer2.3.conv3.weight False\n",
      "ResNet50.layer2.3.bn3.weight False\n",
      "ResNet50.layer2.3.bn3.bias False\n",
      "ResNet50.layer3.0.conv1.weight False\n",
      "ResNet50.layer3.0.bn1.weight False\n",
      "ResNet50.layer3.0.bn1.bias False\n",
      "ResNet50.layer3.0.conv2.weight False\n",
      "ResNet50.layer3.0.bn2.weight False\n",
      "ResNet50.layer3.0.bn2.bias False\n",
      "ResNet50.layer3.0.conv3.weight False\n",
      "ResNet50.layer3.0.bn3.weight False\n",
      "ResNet50.layer3.0.bn3.bias False\n",
      "ResNet50.layer3.0.downsample.0.weight False\n",
      "ResNet50.layer3.0.downsample.1.weight False\n",
      "ResNet50.layer3.0.downsample.1.bias False\n",
      "ResNet50.layer3.1.conv1.weight False\n",
      "ResNet50.layer3.1.bn1.weight False\n",
      "ResNet50.layer3.1.bn1.bias False\n",
      "ResNet50.layer3.1.conv2.weight False\n",
      "ResNet50.layer3.1.bn2.weight False\n",
      "ResNet50.layer3.1.bn2.bias False\n",
      "ResNet50.layer3.1.conv3.weight False\n",
      "ResNet50.layer3.1.bn3.weight False\n",
      "ResNet50.layer3.1.bn3.bias False\n",
      "ResNet50.layer3.2.conv1.weight False\n",
      "ResNet50.layer3.2.bn1.weight False\n",
      "ResNet50.layer3.2.bn1.bias False\n",
      "ResNet50.layer3.2.conv2.weight False\n",
      "ResNet50.layer3.2.bn2.weight False\n",
      "ResNet50.layer3.2.bn2.bias False\n",
      "ResNet50.layer3.2.conv3.weight False\n",
      "ResNet50.layer3.2.bn3.weight False\n",
      "ResNet50.layer3.2.bn3.bias False\n",
      "ResNet50.layer3.3.conv1.weight False\n",
      "ResNet50.layer3.3.bn1.weight False\n",
      "ResNet50.layer3.3.bn1.bias False\n",
      "ResNet50.layer3.3.conv2.weight False\n",
      "ResNet50.layer3.3.bn2.weight False\n",
      "ResNet50.layer3.3.bn2.bias False\n",
      "ResNet50.layer3.3.conv3.weight False\n",
      "ResNet50.layer3.3.bn3.weight False\n",
      "ResNet50.layer3.3.bn3.bias False\n",
      "ResNet50.layer3.4.conv1.weight False\n",
      "ResNet50.layer3.4.bn1.weight False\n",
      "ResNet50.layer3.4.bn1.bias False\n",
      "ResNet50.layer3.4.conv2.weight False\n",
      "ResNet50.layer3.4.bn2.weight False\n",
      "ResNet50.layer3.4.bn2.bias False\n",
      "ResNet50.layer3.4.conv3.weight False\n",
      "ResNet50.layer3.4.bn3.weight False\n",
      "ResNet50.layer3.4.bn3.bias False\n",
      "ResNet50.layer3.5.conv1.weight False\n",
      "ResNet50.layer3.5.bn1.weight False\n",
      "ResNet50.layer3.5.bn1.bias False\n",
      "ResNet50.layer3.5.conv2.weight False\n",
      "ResNet50.layer3.5.bn2.weight False\n",
      "ResNet50.layer3.5.bn2.bias False\n",
      "ResNet50.layer3.5.conv3.weight False\n",
      "ResNet50.layer3.5.bn3.weight False\n",
      "ResNet50.layer3.5.bn3.bias False\n",
      "ResNet50.layer4.0.conv1.weight True\n",
      "ResNet50.layer4.0.bn1.weight True\n",
      "ResNet50.layer4.0.bn1.bias True\n",
      "ResNet50.layer4.0.conv2.weight True\n",
      "ResNet50.layer4.0.bn2.weight True\n",
      "ResNet50.layer4.0.bn2.bias True\n",
      "ResNet50.layer4.0.conv3.weight True\n",
      "ResNet50.layer4.0.bn3.weight True\n",
      "ResNet50.layer4.0.bn3.bias True\n",
      "ResNet50.layer4.0.downsample.0.weight True\n",
      "ResNet50.layer4.0.downsample.1.weight True\n",
      "ResNet50.layer4.0.downsample.1.bias True\n",
      "ResNet50.layer4.1.conv1.weight True\n",
      "ResNet50.layer4.1.bn1.weight True\n",
      "ResNet50.layer4.1.bn1.bias True\n",
      "ResNet50.layer4.1.conv2.weight True\n",
      "ResNet50.layer4.1.bn2.weight True\n",
      "ResNet50.layer4.1.bn2.bias True\n",
      "ResNet50.layer4.1.conv3.weight True\n",
      "ResNet50.layer4.1.bn3.weight True\n",
      "ResNet50.layer4.1.bn3.bias True\n",
      "ResNet50.layer4.2.conv1.weight True\n",
      "ResNet50.layer4.2.bn1.weight True\n",
      "ResNet50.layer4.2.bn1.bias True\n",
      "ResNet50.layer4.2.conv2.weight True\n",
      "ResNet50.layer4.2.bn2.weight True\n",
      "ResNet50.layer4.2.bn2.bias True\n",
      "ResNet50.layer4.2.conv3.weight True\n",
      "ResNet50.layer4.2.bn3.weight True\n",
      "ResNet50.layer4.2.bn3.bias True\n",
      "ResNet50.fc.weight True\n",
      "ResNet50.fc.bias True\n"
     ]
    }
   ],
   "source": [
    "# Layer 4의 required_grad True로 바꾸기 (Layer 4의 시작: 130) -> 130 이전은 false, 이후는 True\n",
    "count = 0\n",
    "for param in resnet50_transfer.ResNet50.parameters():\n",
    "    count += 1\n",
    "    if count >= 130:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "for name, param in resnet50_transfer.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer4의 0번째 bottleneck의 conv1.weight\n",
      "layer4.0.conv1.weight의 conv filter initialization setting 완료\n",
      "\n",
      "layer4의 0번째 bottleneck의 conv2.weight\n",
      "layer4.0.conv2.weight의 conv filter initialization setting 완료\n",
      "\n",
      "layer4의 0번째 bottleneck의 conv3.weight\n",
      "layer4.0.conv3.weight의 conv filter initialization setting 완료\n",
      "\n",
      "layer4의 1번째 bottleneck의 conv1.weight\n",
      "layer4.1.conv1.weight의 conv filter initialization setting 완료\n",
      "\n",
      "layer4의 1번째 bottleneck의 conv2.weight\n",
      "layer4.1.conv2.weight의 conv filter initialization setting 완료\n",
      "\n",
      "layer4의 1번째 bottleneck의 conv3.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer4.1.conv3.weight의 conv filter initialization setting 완료\n",
      "\n",
      "layer4의 2번째 bottleneck의 conv1.weight\n",
      "layer4.2.conv1.weight의 conv filter initialization setting 완료\n",
      "\n",
      "layer4의 2번째 bottleneck의 conv2.weight\n",
      "layer4.2.conv2.weight의 conv filter initialization setting 완료\n",
      "\n",
      "layer4의 2번째 bottleneck의 conv3.weight\n",
      "layer4.2.conv3.weight의 conv filter initialization setting 완료\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Layer 4의 Conv layer를 다시 initialization\n",
    "for name, layer in resnet50_transfer.ResNet50.named_children():\n",
    "    if name == 'layer4':\n",
    "        bottleneck_index = 0\n",
    "        conv_index = 1\n",
    "        for name, param in resnet50_transfer.ResNet50.named_parameters():\n",
    "            # Layer 4의 Conv layer parameter initialization\n",
    "            if name == 'layer4.'+str(bottleneck_index)+'.conv'+str(conv_index)+'.weight':\n",
    "                print('layer4의 '+str(bottleneck_index)+'번째 bottleneck의 conv'+str(conv_index)+'.weight')\n",
    "                nn.init.xavier_uniform_(param)\n",
    "                print(name+'의 conv filter initialization setting 완료')\n",
    "                print()\n",
    "                conv_index += 1\n",
    "                if name == 'layer4.'+str(bottleneck_index)+'.conv3.weight':\n",
    "                    bottleneck_index += 1\n",
    "                    conv_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer4의 0번째 bottleneck의 bn1.weight\n",
      "layer4.0.bn1.weight의 gamma one setting 완료\n",
      "\n",
      "layer4.0.bn1.bias\n",
      "layer4.0.bn1.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 0번째 bottleneck의 bn2.weight\n",
      "layer4.0.bn2.weight의 gamma one setting 완료\n",
      "\n",
      "layer4.0.bn2.bias\n",
      "layer4.0.bn2.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 0번째 bottleneck의 bn3.weight\n",
      "layer4.0.bn3.weight의 gamma zero setting 완료\n",
      "\n",
      "layer4.0.bn3.bias\n",
      "layer4.0.bn3.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 1번째 bottleneck의 bn1.weight\n",
      "layer4.1.bn1.weight의 gamma one setting 완료\n",
      "\n",
      "layer4.1.bn1.bias\n",
      "layer4.1.bn1.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 1번째 bottleneck의 bn2.weight\n",
      "layer4.1.bn2.weight의 gamma one setting 완료\n",
      "\n",
      "layer4.1.bn2.bias\n",
      "layer4.1.bn2.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 1번째 bottleneck의 bn3.weight\n",
      "layer4.1.bn3.weight의 gamma zero setting 완료\n",
      "\n",
      "layer4.1.bn3.bias\n",
      "layer4.1.bn3.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 2번째 bottleneck의 bn1.weight\n",
      "layer4.2.bn1.weight의 gamma one setting 완료\n",
      "\n",
      "layer4.2.bn1.bias\n",
      "layer4.2.bn1.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 2번째 bottleneck의 bn2.weight\n",
      "layer4.2.bn2.weight의 gamma one setting 완료\n",
      "\n",
      "layer4.2.bn2.bias\n",
      "layer4.2.bn2.bias의 beta zero setting 완료\n",
      "\n",
      "layer4의 2번째 bottleneck의 bn3.weight\n",
      "layer4.2.bn3.weight의 gamma zero setting 완료\n",
      "\n",
      "layer4.2.bn3.bias\n",
      "layer4.2.bn3.bias의 beta zero setting 완료\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Layer 4의 batch normalization gamma, beta initialization\n",
    "# 전부 initialization시키므로 처음 시작을 0, 1로 시작, 만약 좀 더 뒤로 바꾸고 싶으면 초기 시작 값을 바꾸기\n",
    "bottleneck_index = 0\n",
    "bn_index = 1\n",
    "for name, param in resnet50_transfer.ResNet50.named_parameters():          \n",
    "    if name == 'layer4.'+str(bottleneck_index)+'.'+'bn1.weight':\n",
    "        print('layer4의 '+str(bottleneck_index)+'번째 bottleneck의 '+'bn1.weight')\n",
    "        nn.init.ones_(param)\n",
    "        print(name+'의 gamma one setting 완료')\n",
    "        print()\n",
    "    elif name == 'layer4.'+str(bottleneck_index)+'.'+'bn2.weight':\n",
    "        print('layer4의 '+str(bottleneck_index)+'번째 bottleneck의 '+'bn2.weight')\n",
    "        nn.init.ones_(param)\n",
    "        print(name+'의 gamma one setting 완료')\n",
    "        print()\n",
    "    elif name == 'layer4.'+str(bottleneck_index)+'.'+'bn3.weight':\n",
    "        print('layer4의 '+str(bottleneck_index)+'번째 bottleneck의 '+'bn3.weight')\n",
    "        nn.init.zeros_(param)\n",
    "        print(name+'의 gamma zero setting 완료')    # residual block 마지막의 batchnorm의 gamma는 0으로, 나머지는 1로 초기화시킨다고 함\n",
    "        print()\n",
    "    elif name == 'layer4.'+str(bottleneck_index)+'.'+'bn'+str(bn_index)+'.bias':\n",
    "        print('layer4.'+str(bottleneck_index)+'.'+'bn'+str(bn_index)+'.bias')     # bias는 0으로 초기화\n",
    "        nn.init.zeros_(param)\n",
    "        bn_index += 1\n",
    "        print(name+'의 beta zero setting 완료')\n",
    "        if bn_index == 4:\n",
    "            bn_index=1\n",
    "            bottleneck_index += 1\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
